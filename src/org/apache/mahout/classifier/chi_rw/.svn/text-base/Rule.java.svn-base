package org.apache.mahout.classifier.chi_rw;

import java.io.DataInput;
import java.io.DataOutput;
import java.io.IOException;

import org.apache.hadoop.io.Writable;
import org.apache.mahout.classifier.chi_rw.data.Data;
import org.apache.mahout.classifier.chi_rw.data.Dataset;
import org.apache.mahout.classifier.chi_rw.mapreduce.*;

public class Rule implements Writable{

	  Fuzzy[] antecedent;
	  int clas;
	  double weight;
	  int compatibilityType;

	  /**
	   * Default constructor
	   */
	  public Rule() {
	  }

	  /**
	   * Constructor with parameters
	   * @param n_variables int
	   * @param compatibilityType int
	   */
	  public Rule(int n_variables, int compatibilityType) {
	    antecedent = new Fuzzy[n_variables];
	    this.compatibilityType = compatibilityType;
	  }

	  /**
	   * It assigns the class of the rule
	   * @param clas int
	   */
	  public void setClass(int clas) {
	    this.clas = clas;
	  }
	  
	  public void setWeight(double weight) {
	    this.weight = weight;
	  }
	  
	  public int getClas(){
		return clas;
	  }
	  
	  public double getWeight(){
		return weight;
	  }

	  /**
	   * It assigns the rule weight to the rule
	   * @param train myDataset the training set
	   * @param ruleWeight int the type of rule weight
	   */	  
	  public void assingConsequent(Data train, int ruleWeight) {
	    if (ruleWeight == BuildModel.CF) {
		  consequent_CF(train);
		}
		else if (ruleWeight == BuildModel.PCF_II) {
		  consequent_PCF2(train);
		}
		else if (ruleWeight == BuildModel.PCF_IV) {
		  consequent_PCF4(train);
		}
		else if (ruleWeight == BuildModel.NO_RW) {
		  weight = 1.0;
		}
      }

	  /**
	   * It computes the compatibility of the rule with an input example
	   * @param example double[] The input example
	   * @return double the degree of compatibility
	   */
	  public double compatibility(double[] example) {
	    if (compatibilityType == BuildModel.MINIMUM) {
	      return minimumCompatibility(example);
	    }
	    else {
	      return productCompatibility(example);
	    }
	  }

	  /**
	   * Operator T-min
	   * @param example double[] The input example
	   * @return double the computation the the minimum T-norm
	   */
	  private double minimumCompatibility(double[] example) {
	    double minimum, membershipDegree;
	    minimum = 1.0;
	    for (int i = 0; i < antecedent.length; i++) {
	      membershipDegree = antecedent[i].Fuzzify(example[i]);
	      minimum = Math.min(membershipDegree, minimum);
	    }
	    return (minimum);

	  }

	  /**
	   * Operator T-product
	   * @param example double[] The input example
	   * @return double the computation the the product T-norm
	   */
	  private double productCompatibility(double[] example) {
	    double product, membershipDegree;
	    product = 1.0;
	    for (int i = 0; i < antecedent.length; i++) {
	      membershipDegree = antecedent[i].Fuzzify(example[i]);
	      product = product * membershipDegree;
	    }
	    return (product);
	  }

	  /**
	   * Classic Certainty Factor weight
	   * @param train myDataset training dataset
	   */
	  private void consequent_CF(Data train) {
		Dataset dataset = train.getDataset();  
	    double[] classes_sum = new double[dataset.nblabels()];
		for (int i = 0; i < dataset.nblabels(); i++) {
		  classes_sum[i] = 0.0;
		}

		double total = 0.0;
		double comp;
		/* Computation of the sum by classes */
		for (int i = 0; i < train.size(); i++) {
		  comp = this.compatibility(train.get(i).get());
		  classes_sum[(int) dataset.getLabel(train.get(i))] += comp;
		  total += comp;
		}
		weight = classes_sum[clas] / total;
     }

	  /**
	   * Penalized Certainty Factor weight II (by Ishibuchi)
	   * @param train myDataset training dataset
	   */
	  private void consequent_PCF2(Data train) {
	    Dataset dataset = train.getDataset();
		double[] classes_sum = new double[dataset.nblabels()];
		for (int i = 0; i < dataset.nblabels(); i++) {
		  classes_sum[i] = 0.0;
		}

		double total = 0.0;
		double comp;
		/* Computation of the sum by classes */
		for (int i = 0; i < train.size(); i++) {
		  comp = this.compatibility(train.get(i).get());
		  classes_sum[(int) dataset.getLabel(train.get(i))] += comp;
		  total += comp;
		}
		double sum = (total - classes_sum[clas]) / (dataset.nblabels() - 1.0);
		weight = (classes_sum[clas] - sum) / total;
	  }

	  /**
	   * Penalized Certainty Factor weight IV (by Ishibuchi)
	   * @param train myDataset training dataset
	   */  
	  private void consequent_PCF4(Data train) {
	    Dataset dataset = train.getDataset();
		double[] classes_sum = new double[dataset.nblabels()];
		for (int i = 0; i < dataset.nblabels(); i++) {
		  classes_sum[i] = 0.0;
		}

		double total = 0.0;
		double comp;
		/* Computation of the sum by classes */
		for (int i = 0; i < train.size(); i++) {
		  comp = this.compatibility(train.get(i).get());
		  classes_sum[(int) dataset.getLabel(train.get(i))] += comp;
		  total += comp;
		 }
		 double sum = total - classes_sum[clas];
		 weight = (classes_sum[clas] - sum) / total;
	   }
	  /**
	   * This function detects if one rule is already included in the Rule Set
	   * @param r Rule Rule to compare
	   * @return boolean true if the rule already exists, else false
	   */
	  public boolean[] comparison_reduce(Rule r) {
	    for (int j = 0; j < antecedent.length; j++) {
	      if (this.antecedent[j].label != r.antecedent[j].label) {
	    	  return new boolean[]{false, false};
	      }
	    }
	    if (this.clas != r.clas) { 	            
	    	return new boolean[]{true, true};
	    }
	    return new boolean[]{true, false};
	  }
	  
	  /**
	   * This function detects if one rule is already included in the Rule Set
	   * @param r Rule Rule to compare
	   * @return boolean true if the rule already exists, else false
	   */
	  public boolean comparison(Rule r) {
	    for (int j = 0; j < antecedent.length; j++) {
	      if (this.antecedent[j].label != r.antecedent[j].label) {
	        return false;
	      }
	    }
	    if (this.clas != r.clas) { //Comparison of the rule weights
	      if (this.weight < r.weight) {
	        //Rule Update
	        this.clas = r.clas;
	        this.weight = r.weight;
	      }
	    }
	    return true;
	  }

	@Override
	public void readFields(DataInput in) throws IOException {
		// TODO Auto-generated method stub
		int antecedent_size = in.readInt();
		antecedent = new Fuzzy[antecedent_size];
		for (int i = 0 ; i < antecedent.length ; i++){
			antecedent[i] = new Fuzzy();
			antecedent[i].readFields(in);
		}
		
		clas = in.readInt();
		weight = in.readDouble();
		compatibilityType = in.readInt();		
	}

	@Override
	public void write(DataOutput out) throws IOException {
		// TODO Auto-generated method stub
		out.writeInt(antecedent.length);
		for (int i = 0 ; i < antecedent.length ; i++)
			antecedent[i].write(out);
		
		out.writeInt(clas);
		out.writeDouble(weight);
		out.writeInt(compatibilityType);		
	}
}

